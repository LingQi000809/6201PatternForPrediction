{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ef05c0a",
   "metadata": {},
   "source": [
    "### Mel Spectrogram -> Audio\n",
    "\n",
    "https://huggingface.co/kashif/soundstream_mel_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d750eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SAMPLE_RATE = 16000\n",
    "N_FFT = 1024\n",
    "HOP_LENGTH = 320\n",
    "WIN_LENGTH = 640\n",
    "N_MEL_CHANNELS = 128\n",
    "MEL_FMIN = 0.0\n",
    "MEL_FMAX = int(SAMPLE_RATE // 2)\n",
    "CLIP_VALUE_MIN = 1e-5\n",
    "CLIP_VALUE_MAX = 1e8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f93432d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ling/Desktop/GT/6201AudioContentAnalysis/PatternForPrediction'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea0b350",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/2l9p7g8n0jjb9kjwgl6q8slw0000gn/T/ipykernel_40921/1574074481.py:5: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load('./datasets/PPDD-Jul2018_aud_mono_small/cont_foil_wav/PatternForPrediction/datasets/PPDD-Jul2018_aud_mono_small/cont_foil_wav/0a983538-61b5-4b9d-9ad9-23e05f548e5c.wav')\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './datasets/PPDD-Jul2018_aud_mono_small/cont_foil_wav/PatternForPrediction/datasets/PPDD-Jul2018_aud_mono_small/cont_foil_wav/0a983538-61b5-4b9d-9ad9-23e05f548e5c.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/GT/6201AudioContentAnalysis/venv_aca/lib/python3.12/site-packages/librosa/core/audio.py:176\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__soundfile_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sf\u001b[38;5;241m.\u001b[39mSoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/GT/6201AudioContentAnalysis/venv_aca/lib/python3.12/site-packages/librosa/core/audio.py:209\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n",
      "File \u001b[0;32m~/Desktop/GT/6201AudioContentAnalysis/venv_aca/lib/python3.12/site-packages/soundfile.py:690\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd, compression_level, bitrate_mode)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[1;32m    689\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[0;32m--> 690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/GT/6201AudioContentAnalysis/venv_aca/lib/python3.12/site-packages/soundfile.py:1265\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1264\u001b[0m     err \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_error(file_ptr)\n\u001b[0;32m-> 1265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError opening \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode_int \u001b[38;5;241m==\u001b[39m _snd\u001b[38;5;241m.\u001b[39mSFM_WRITE:\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[1;32m   1268\u001b[0m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[1;32m   1269\u001b[0m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
      "\u001b[0;31mLibsndfileError\u001b[0m: Error opening './datasets/PPDD-Jul2018_aud_mono_small/cont_foil_wav/PatternForPrediction/datasets/PPDD-Jul2018_aud_mono_small/cont_foil_wav/0a983538-61b5-4b9d-9ad9-23e05f548e5c.wav': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlibrosa\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load and normalize audio\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m y, sr \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./datasets/PPDD-Jul2018_aud_mono_small/cont_foil_wav/PatternForPrediction/datasets/PPDD-Jul2018_aud_mono_small/cont_foil_wav/0a983538-61b5-4b9d-9ad9-23e05f548e5c.wav\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m y, _ \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39meffects\u001b[38;5;241m.\u001b[39mtrim(y)\n\u001b[1;32m      7\u001b[0m y \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mnormalize(y)\n",
      "File \u001b[0;32m~/Desktop/GT/6201AudioContentAnalysis/venv_aca/lib/python3.12/site-packages/librosa/core/audio.py:184\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPurePath)):\n\u001b[1;32m    181\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    183\u001b[0m     )\n\u001b[0;32m--> 184\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__audioread_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/Desktop/GT/6201AudioContentAnalysis/venv_aca/lib/python3.12/site-packages/decorator.py:235\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    234\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/GT/6201AudioContentAnalysis/venv_aca/lib/python3.12/site-packages/librosa/util/decorators.py:63\u001b[0m, in \u001b[0;36mdeprecated.<locals>.__wrapper\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Warn the user, and then proceed.\"\"\"\u001b[39;00m\n\u001b[1;32m     55\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mDeprecated as of librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mIt will be removed in librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# Would be 2, but the decorator adds a level\u001b[39;00m\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/GT/6201AudioContentAnalysis/venv_aca/lib/python3.12/site-packages/librosa/core/audio.py:240\u001b[0m, in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    237\u001b[0m     reader \u001b[38;5;241m=\u001b[39m path\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# If the input was not an audioread object, try to open it\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m     reader \u001b[38;5;241m=\u001b[39m \u001b[43maudioread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m reader \u001b[38;5;28;01mas\u001b[39;00m input_file:\n\u001b[1;32m    243\u001b[0m     sr_native \u001b[38;5;241m=\u001b[39m input_file\u001b[38;5;241m.\u001b[39msamplerate\n",
      "File \u001b[0;32m~/Desktop/GT/6201AudioContentAnalysis/venv_aca/lib/python3.12/site-packages/audioread/__init__.py:127\u001b[0m, in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m BackendClass \u001b[38;5;129;01min\u001b[39;00m backends:\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBackendClass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m DecodeError:\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/GT/6201AudioContentAnalysis/venv_aca/lib/python3.12/site-packages/audioread/rawread.py:59\u001b[0m, in \u001b[0;36mRawAudioFile.__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename):\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m aifc\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './datasets/PPDD-Jul2018_aud_mono_small/cont_foil_wav/PatternForPrediction/datasets/PPDD-Jul2018_aud_mono_small/cont_foil_wav/0a983538-61b5-4b9d-9ad9-23e05f548e5c.wav'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "# Load and normalize audio\n",
    "y, sr = librosa.load('./datasets/PPDD-Jul2018_aud_mono_small/prime_wav/0a983538-61b5-4b9d-9ad9-23e05f548e5c.wav')\n",
    "y, _ = librosa.effects.trim(y)\n",
    "y = librosa.util.normalize(y)\n",
    "\n",
    "S = librosa.feature.melspectrogram(\n",
    "    y=y, \n",
    "    sr=SAMPLE_RATE, \n",
    "    n_fft=N_FFT,\n",
    "    hop_length=HOP_LENGTH,\n",
    "    win_length=WIN_LENGTH,\n",
    "    n_mels=N_MEL_CHANNELS,\n",
    "    fmin=MEL_FMIN,\n",
    "    fmax=MEL_FMAX,\n",
    ")\n",
    "\n",
    "# Clip manually before log conversion\n",
    "mel = np.clip(S, CLIP_VALUE_MIN, CLIP_VALUE_MAX)\n",
    "# mel = np.log10(S)   # the model expects a log-magnitude Mel spectrogram\n",
    "# mel = mel[np.newaxis, :, :]  The model expects shape(1, n_mels, n_frames) \n",
    "\n",
    "from diffusers import OnnxRuntimeModel\n",
    "from IPython.display import Audio\n",
    "\n",
    "melgan = OnnxRuntimeModel.from_pretrained(\"kashif/soundstream_mel_decoder\")\n",
    "\n",
    "audio = melgan(input_features=mel.astype(np.float32))\n",
    "Audio(audio, rate=SAMPLE_RATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15b7a266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'd', 'e']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list([\"a\", \"b\", \"c\", \"d\", \"e\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29f56c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c31ae90e-c752-495e-ba45-1982f50c612b.csv',\n",
       " 'd42c9e96-a8d6-466f-9056-9f019ef0ff5f.csv',\n",
       " '61e8409b-b1e0-4ca2-a62c-2685bb4eb870.csv',\n",
       " '7d83865a-1d0e-41ad-b4a8-ec76cc5bcf8c.csv',\n",
       " 'dd1e320f-13d3-4b9a-a543-4e8a600263d3.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.listdir(\"./datasets/PPDD-Jul2018_aud_mono_small/prime_csv\")[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54888f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 2, 3, 4]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2, 3]\n",
    "b = [2, 3, 4]\n",
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf41a22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ling/Desktop/GT/6201AudioContentAnalysis/6201PatternForPrediction'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c559864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148.75\n",
      "148.83333\n",
      "149.0\n",
      "149.33333\n",
      "149.5\n",
      "149.66667\n",
      "149.83333\n",
      "150.75\n",
      "150.83333\n",
      "151.0\n",
      "151.33333\n",
      "151.5\n",
      "151.66667\n",
      "151.83333\n",
      "153.83333\n",
      "154.0\n",
      "154.33333\n",
      "156.75\n",
      "156.83333\n",
      "157.0\n",
      "157.33333\n",
      "157.5\n",
      "157.66667\n",
      "157.83333\n",
      "158.75\n",
      "158.83333\n",
      "159.0\n",
      "159.33333\n",
      "159.5\n",
      "159.66667\n",
      "159.83333\n",
      "161.83333\n",
      "162.0\n",
      "162.33333\n",
      "164.5\n",
      "164.83333\n",
      "165.33333\n",
      "165.66667\n",
      "165.83333\n",
      "166.0\n",
      "166.5\n",
      "166.83333\n",
      "167.83333\n",
      "168.0\n",
      "168.5\n",
      "168.83333\n",
      "169.33333\n",
      "169.5\n",
      "169.83333\n",
      "174.75\n",
      "174.83333\n",
      "175.0\n",
      "175.33333\n",
      "175.5\n",
      "175.66667\n",
      "175.83333\n",
      "176.66667\n",
      "176.83333\n",
      "177.0\n",
      "177.33333\n",
      "177.5\n",
      "177.66667\n",
      "177.83333\n",
      "179.83333\n",
      "180.0\n",
      "180.25\n",
      "182.66667\n",
      "182.83333\n",
      "183.0\n",
      "183.33333\n",
      "183.5\n",
      "183.66667\n",
      "183.83333\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open(\"./datasets/PPDD-Jul2018_aud_mono_small/prime_csv/96a93bb4-f274-4bef-9db2-aa3cdeaad1a1.csv\", \"r\", encoding=\"utf-8\") as f:  # open in binary mode\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        if not row or all(cell.strip() == \"\" for cell in row):\n",
    "            continue  # skip empty lines\n",
    "        print(float(row[0]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee8ffa10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly chosen d99f6dd9-8f68-4962-97ff-036a72051e5c.csv as the test file.\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x80 in position 3131: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 301\u001b[0m\n\u001b[1;32m    299\u001b[0m cont_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(cont_csv_dir, cont_csv_files[i])\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m--> 301\u001b[0m onset_offset \u001b[38;5;241m=\u001b[39m \u001b[43mget_onset_offset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprime_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m prime_pitch_seq, prime_onset_seq \u001b[38;5;241m=\u001b[39m get_seqs_from_csv(prime_file, onset_offset)\n\u001b[1;32m    303\u001b[0m cont_pitch_seq, cont_onset_seq \u001b[38;5;241m=\u001b[39m get_seqs_from_csv(cont_file, onset_offset)\n",
      "File \u001b[0;32m~/Desktop/GT/6201AudioContentAnalysis/6201PatternForPrediction/preprocessing.py:52\u001b[0m, in \u001b[0;36mget_onset_offset\u001b[0;34m(csv_file)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(csv_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     51\u001b[0m     reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(f)\n\u001b[0;32m---> 52\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mcontinue\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# skip empty lines\u001b[39;49;00m\n",
      "File \u001b[0;32m<frozen codecs>:322\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x80 in position 3131: invalid start byte"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from enum import Enum\n",
    "\n",
    "class CsvColumns(Enum):\n",
    "    ONSET = 0      # Time of the note (quarter-note beats)\n",
    "    MIDI = 1          # MIDI note number\n",
    "    MORPHETIC = 2  # Morph pitch number\n",
    "    DUR = 3            # Duration in beats\n",
    "    CHAN = 4       # MIDI channel\n",
    "\n",
    "REST_STATE = \"r\"\n",
    "\n",
    "def get_seqs_from_csv(csv_file: str, onset_offset: float):\n",
    "    pitch_seq = []\n",
    "    onset_seq = []\n",
    "\n",
    "    events = []\n",
    "    with open(csv_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            if not row or all(cell.strip() == \"\" for cell in row):\n",
    "                continue  # skip empty lines\n",
    "            # Convert all to float first\n",
    "            events.append([float(cell) for cell in row])\n",
    "\n",
    "    n = len(events)\n",
    "    for i in range(n):\n",
    "        onset = events[i][CsvColumns.ONSET.value] - onset_offset\n",
    "        pitch = events[i][CsvColumns.MIDI.value]\n",
    "        dur = events[i][CsvColumns.DUR.value]\n",
    "\n",
    "        # append pitch\n",
    "        pitch_seq.append(pitch)\n",
    "\n",
    "        # add onset / rest logic\n",
    "        onset_seq.append(pitch)\n",
    "        if i < n - 1:\n",
    "            next_onset = events[i+1][CsvColumns.ONSET.value] - onset_offset\n",
    "            gap = next_onset - (onset + dur)\n",
    "            if gap > 0:\n",
    "                pitch_seq.append(REST_STATE)\n",
    "                onset_seq.append(gap)\n",
    "\n",
    "    return pitch_seq, onset_seq\n",
    "\n",
    "def get_onset_offset(csv_file: str):\n",
    "    # Onsets do not necessarily start at 0. \n",
    "    # We subtract the first onset from all subsequent onsets so that each song begins at 0.\n",
    "    # This normalization ensures between-song normalization during training.\n",
    "    with open(csv_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            if not row or all(cell.strip() == \"\" for cell in row):\n",
    "                continue  # skip empty lines\n",
    "            return float(row[CsvColumns.ONSET.value])\n",
    "    raise ValueError(f\"No valid rows found in {csv_file}\")\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "class VariableOrderMarkov:\n",
    "    \"\"\"\n",
    "    Variable-order Markov Model.\n",
    "    Stores n-grams probability distribution for all orders from 1..max_order.\n",
    "    Allows generating sequences with lower order than training order.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, max_order=3):\n",
    "        # order is the numeric value n in n-gram.\n",
    "        self.max_order = max_order\n",
    "\n",
    "        # counts for each n-gram\n",
    "        #   -> counts[1]: counts for each 1-gram\n",
    "        #       -> {1-gram context: {next state: count}}\n",
    "        #   -> counts[2]: counts for each 2-gram\n",
    "        #       -> {2-gram context: {next state: count}}\n",
    "        #   -> etc...\n",
    "        self.counts = {\n",
    "            k: defaultdict(lambda: defaultdict(float))\n",
    "            for k in range(1, max_order + 1)\n",
    "        }\n",
    "\n",
    "        # transition probability for each n-gram\n",
    "        self.probs = {\n",
    "            k: defaultdict(lambda: defaultdict(float))\n",
    "            for k in range(1, max_order + 1)\n",
    "        }\n",
    "\n",
    "        # all unique states (our vocab)\n",
    "        self.states = set()\n",
    "\n",
    "        # tracks whether probabilities are up to date.\n",
    "        self.is_trained = False\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Training\n",
    "    # - called for each audio piece\n",
    "    # -----------------------------------------------------\n",
    "    def train(self, seq):\n",
    "        L = len(seq)\n",
    "        if L < 2:\n",
    "            return\n",
    "        for i in range(L):\n",
    "            self.states.add(seq[i])\n",
    "        for order in range(1, self.max_order + 1):\n",
    "            for i in range(order, L):\n",
    "                context = tuple(seq[i - order:i])\n",
    "                nxt = seq[i]\n",
    "                self.counts[order][context][nxt] += 1\n",
    "        self.is_trained = False\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Probability computation\n",
    "    # - called after all pieces are trained\n",
    "    # -----------------------------------------------------\n",
    "    def compute_probabilities(self):\n",
    "        for order in range(1, self.max_order + 1):\n",
    "            for context, next_counts in self.counts[order].items():\n",
    "                total = sum(next_counts.values())\n",
    "                if total == 0:\n",
    "                    continue\n",
    "                for nxt, count in next_counts.items():\n",
    "                    self.probs[order][context][nxt] = count / total\n",
    "\n",
    "        self.is_trained = True\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Generation\n",
    "    # -----------------------------------------------------\n",
    "    def generate(self, generate_length, seq_prime=None, order=None):\n",
    "        \"\"\"\n",
    "        generate_length: total number of states to generate after the prime\n",
    "        order: which order to generate with (1..max_order)\n",
    "        seq_prime: optional priming sequence (list)\n",
    "        \"\"\"\n",
    "        if not self.is_trained:\n",
    "            self.compute_probabilities()\n",
    "\n",
    "        if order is None:\n",
    "            order = self.max_order\n",
    "\n",
    "        if seq_prime is None:\n",
    "            seq_prime = [np.random.choice(list(self.states))]\n",
    "        prime_len = len(seq_prime)\n",
    "        seq = list(seq_prime)\n",
    "\n",
    "        while len(seq) - prime_len < generate_length:\n",
    "            context = tuple(seq[-order:]) if len(seq) >= order else tuple(seq)\n",
    "\n",
    "            # Try decreasing orders until we find a valid context\n",
    "            o = min(order, len(context))\n",
    "            next_state = None\n",
    "\n",
    "            while o > 0 and next_state is None:\n",
    "                c = tuple(context[-o:])\n",
    "                dist = self.probs[o].get(c, None)\n",
    "                if dist:\n",
    "                    next_state = np.random.choice(\n",
    "                        list(dist.keys()),\n",
    "                        p=list(dist.values())\n",
    "                    )\n",
    "                else:\n",
    "                    o -= 1\n",
    "\n",
    "            # If no context found at any order → random fallback\n",
    "            if next_state is None:\n",
    "                next_state = np.random.choice(list(self.states))\n",
    "\n",
    "            seq.append(next_state)\n",
    "\n",
    "        return seq[prime_len:]  # only return the generated continuation\n",
    "\n",
    "\n",
    "\n",
    "import csv\n",
    "import fluidsynth\n",
    "from mido import MidiFile, MidiTrack, Message\n",
    "from preprocessing import CsvColumns\n",
    "\n",
    "def sequence_to_midi(\n",
    "        midi_file_path, \n",
    "        onset_offset, pitch_seq, onset_seq, \n",
    "        csv_file_path = None,\n",
    "        velocity=64):\n",
    "    \"\"\"\n",
    "    Convert pitch + onset sequences into a MIDI file and optionally export to CSV.\n",
    "    \n",
    "    Args:\n",
    "        onset_offset: first onset to normalize sequence\n",
    "        pitch_seq: list of pitches (with 'r' for rests)\n",
    "        onset_seq: list of onsets in quarter-note beats\n",
    "        midi_file_path: path to save MIDI\n",
    "        csv_file_path: optional path to save CSV\n",
    "        velocity: MIDI note velocity\n",
    "    \"\"\"\n",
    "    assert len(pitch_seq) == len(onset_seq), \"pitch_seq and onset_seq must be same length\"\n",
    "\n",
    "    mid = MidiFile()\n",
    "    track = MidiTrack()\n",
    "    mid.tracks.append(track)\n",
    "\n",
    "    csv_rows = []\n",
    "    tick_from_prev_note = 0\n",
    "    for i, pitch in enumerate(pitch_seq):\n",
    "        onset = onset_seq[i] - onset_offset\n",
    "\n",
    "        # compute note duration as time until next onset\n",
    "        if i+1 >= len(onset_seq):\n",
    "            # last note → set a default short duration\n",
    "            next_onset = onset + 0.25  # quarter-beat default\n",
    "        else:\n",
    "            next_onset = onset_seq[i+1] - onset_offset\n",
    "        note_duration_beats = next_onset - onset\n",
    "        note_duration_ticks = int(note_duration_beats * mid.ticks_per_beat)\n",
    "\n",
    "        if pitch != \"r\":\n",
    "            # the time for note_on and note_off events is always the delta tick from the pervious event\n",
    "            track.append(Message('note_on', note=int(pitch), velocity=velocity, time=tick_from_prev_note))\n",
    "            track.append(Message('note_off', note=int(pitch), velocity=velocity, time=note_duration_ticks))\n",
    "\n",
    "            tick_from_prev_note = 0\n",
    "\n",
    "            # Add row for CSV\n",
    "            if csv_file_path:\n",
    "                csv_rows.append({\n",
    "                    CsvColumns.ONSET.value: onset,\n",
    "                    CsvColumns.MIDI.value: pitch,\n",
    "                    CsvColumns.DUR.value: note_duration_beats\n",
    "                })\n",
    "        else:\n",
    "            # rest → no note, just advance prev_onset\n",
    "            tick_from_prev_note = note_duration_ticks\n",
    "\n",
    "    mid.save(midi_file_path)\n",
    "    print(f\"MIDI saved to {midi_file_path}\")\n",
    "\n",
    "    # Save CSV if path provided\n",
    "    if csv_file_path:\n",
    "        with open(csv_file_path, \"w\", newline=\"\") as f:\n",
    "            writer = csv.DictWriter(f)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(csv_rows)\n",
    "        print(f\"CSV saved to {csv_file_path}\")\n",
    "    return midi_file_path\n",
    "\n",
    "def midi_to_wav(midi_file, wav_file, soundfont=\"FluidR3_GM.sf2\"):\n",
    "    \"\"\"\n",
    "    Render a MIDI file to WAV using FluidSynth.\n",
    "    \"\"\"\n",
    "    fs = fluidsynth.Synth()\n",
    "    fs.start(driver=\"file\", filename=wav_file)\n",
    "    sfid = fs.sfload(soundfont)\n",
    "    fs.program_select(0, sfid, 0, 0)\n",
    "    \n",
    "    fs.midi_file_play(midi_file)\n",
    "    fs.delete()\n",
    "    \n",
    "    print(f\"WAV saved to {wav_file}\")\n",
    "    return wav_file\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from markov import VariableOrderMarkov\n",
    "from preprocessing import get_seqs_from_csv, get_onset_offset\n",
    "from postprocessing import sequence_to_midi, midi_to_wav\n",
    "\n",
    "\n",
    "# initialize parallel markov models for pitch and onset respectively\n",
    "max_order = 2\n",
    "generate_length = 10\n",
    "pitch_markov = VariableOrderMarkov(max_order=max_order)\n",
    "onset_markov = VariableOrderMarkov(max_order=max_order)\n",
    "\n",
    "# get all CSV files from prime and continuation directory\n",
    "prime_csv_dir = \"./datasets/PPDD-Jul2018_aud_mono_small/prime_csv\"\n",
    "cont_csv_dir = \"./datasets/PPDD-Jul2018_aud_mono_small/cont_true_csv\"\n",
    "prime_midi_dir = \"./datasets/PPDD-Jul2018_aud_mono_small/prime_midi\"\n",
    "cont_midi_dir = \"./datasets/PPDD-Jul2018_aud_mono_small/cont_true_midi\"\n",
    "prime_wav_dir = \"./datasets/PPDD-Jul2018_aud_mono_small/prime_wav\"\n",
    "cont_wav_dir = \"./datasets/PPDD-Jul2018_aud_mono_small/cont_true_wav\"\n",
    "prime_csv_files = os.listdir(prime_csv_dir)\n",
    "cont_csv_files = os.listdir(cont_csv_dir)\n",
    "num_files = len(prime_csv_files)\n",
    "assert num_files == len(cont_csv_files), \"prime directory and continuation directory must have the same number of files\"\n",
    "\n",
    "test_file_index = random.randrange(start=0, stop=num_files)\n",
    "test_file_id = prime_csv_files[test_file_index]\n",
    "print(f\"Randomly chosen {test_file_id} as the test file.\")\n",
    "assert test_file_id == cont_csv_files[test_file_index], \"prime directory and continuation directory must have the same number of files in the same order\" \n",
    "\n",
    "# train both markov models\n",
    "for i in range(num_files):\n",
    "    prime_file = os.path.join(prime_csv_dir, prime_csv_files[i])\n",
    "    cont_file = os.path.join(cont_csv_dir, cont_csv_files[i])\n",
    "    print(i)\n",
    "    onset_offset = get_onset_offset(prime_file)\n",
    "    prime_pitch_seq, prime_onset_seq = get_seqs_from_csv(prime_file, onset_offset)\n",
    "    cont_pitch_seq, cont_onset_seq = get_seqs_from_csv(cont_file, onset_offset)\n",
    "    pitch_markov.train(prime_pitch_seq + cont_pitch_seq)\n",
    "    onset_markov.train(prime_onset_seq + cont_onset_seq)\n",
    "\n",
    "# generate for test file\n",
    "test_prime_csv = os.path.join(prime_csv_dir, test_file_id)\n",
    "test_cont_csv = os.path.join(cont_csv_dir, test_file_id)\n",
    "onset_offset = get_onset_offset(test_prime_csv)\n",
    "pitch_seq_prime, onset_seq_prime = get_seqs_from_csv(test_prime_csv, onset_offset)\n",
    "true_pitch_cont, true_onset_cont = get_seqs_from_csv(test_cont_csv, onset_offset)\n",
    "generated_pitch_cont = pitch_markov.generate(generate_length, seq_prime=pitch_seq_prime)\n",
    "generated_onset_cont = onset_markov.generate(generate_length, seq_prime=onset_seq_prime)\n",
    "\n",
    "# write outputs\n",
    "output_dir = f\"./test_generation/{test_file_id}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "midi_filepath = sequence_to_midi(\n",
    "    os.path.join(output_dir, \"generated_cont.mid\"), \n",
    "    onset_offset,\n",
    "    generated_pitch_cont,\n",
    "    generated_onset_cont,\n",
    "    csv_file_path=os.path.join(output_dir, \"generated_cont.csv\"),\n",
    ")\n",
    "wav_filepath = midi_to_wav(\n",
    "    midi_filepath,\n",
    "    os.path.join(output_dir, \"generated_cont.wav\")\n",
    ")\n",
    "# copy prime and true continuation files\n",
    "shutil.copy(test_prime_csv, os.path.join(output_dir, \"prime.csv\"))\n",
    "shutil.copy(test_cont_csv, os.path.join(output_dir, \"true_cont.csv\"))\n",
    "shutil.copy(os.path.join(prime_midi_dir, test_file_id), os.path.join(output_dir, \"prime.midi\"))\n",
    "shutil.copy(os.path.join(cont_midi_dir, test_file_id), os.path.join(output_dir, \"true_cont.midi\"))\n",
    "shutil.copy(os.path.join(prime_wav_dir, test_file_id), os.path.join(output_dir, \"prime.wav\"))\n",
    "shutil.copy(os.path.join(cont_wav_dir, test_file_id), os.path.join(output_dir, \"true_cont.wav\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2c0856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/PPDD-Jul2018_aud_mono_small/prime_csv/.DS_Store\n",
      "<_csv.reader object at 0x10b9dd150>\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x80 in position 3131: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(f)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(reader)\n\u001b[0;32m----> 6\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mcontinue\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# skip empty lines\u001b[39;49;00m\n",
      "File \u001b[0;32m<frozen codecs>:322\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x80 in position 3131: invalid start byte"
     ]
    }
   ],
   "source": [
    "csv_file = os.path.join(prime_csv_dir, prime_csv_files[15])\n",
    "print(csv_file)\n",
    "with open(csv_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            if not row or all(cell.strip() == \"\" for cell in row):\n",
    "                continue  # skip empty lines\n",
    "            print(float(row[CsvColumns.ONSET.value]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_aca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
